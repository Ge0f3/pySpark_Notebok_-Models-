{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EUFLpHXmsIE",
        "outputId": "3514800f-1f4c-443e-a663-19e876ebd436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824028 sha256=f049855bdeb6fc3fb55581f7daff5f610e3df8035116e7633b2a0ab9a3008272\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade pyspark\n",
        "! pip install scikit-learn --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import pyspark.sql.functions as sqlfunc\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate() \n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "20vQeLx8mxxr",
        "outputId": "fb2f4a5d-87fb-4314-d6b5-9670cfad181b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f0cb538aee0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://db28e86e2500:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://mldataset0123.s3.amazonaws.com/original.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Et9PAujm2Tk",
        "outputId": "9742f5d5-6db4-4531-e849-50aaef709670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-20 01:44:24--  https://mldataset0123.s3.amazonaws.com/original.csv\n",
            "Resolving mldataset0123.s3.amazonaws.com (mldataset0123.s3.amazonaws.com)... 54.231.202.81, 54.231.233.177, 54.231.168.201, ...\n",
            "Connecting to mldataset0123.s3.amazonaws.com (mldataset0123.s3.amazonaws.com)|54.231.202.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 86874 (85K) [text/csv]\n",
            "Saving to: ‘original.csv’\n",
            "\n",
            "original.csv        100%[===================>]  84.84K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-03-20 01:44:25 (1.49 MB/s) - ‘original.csv’ saved [86874/86874]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('original.csv',header=True)"
      ],
      "metadata": {
        "id": "Ykdk-jGHr1Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"Salary\", sqlfunc.regexp_replace(sqlfunc.col(\"Salary\"), \"[\\$,]\", \"\").alias(\"Salary\"))\n",
        "df = df.withColumn(\"Salary\", df.Salary.cast('float'))\n",
        "df = df.withColumn(\"Latitude\", df.Salary.cast('float'))\n",
        "df = df.withColumn(\"Longitude\", df.Salary.cast('float'))"
      ],
      "metadata": {
        "id": "q2blkylfvswc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['id', 'first_name','last_name']\n",
        "df = df.drop(*columns_to_drop)\n",
        "df = df.na.drop()"
      ],
      "metadata": {
        "id": "LMqZWvwowzo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwkRa1g1v2eJ",
        "outputId": "6e09e075-5dc6-4acc-cb2f-2d3b75a8f022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------------+--------------------+--------+--------+---------+\n",
            "|gender|           City|            JobTitle|  Salary|Latitude|Longitude|\n",
            "+------+---------------+--------------------+--------+--------+---------+\n",
            "|Female|      Nowa Ruda| Assistant Professor|57438.18|57438.18| 57438.18|\n",
            "|Female|         Bulgan|       Programmer II| 62846.6| 62846.6|  62846.6|\n",
            "|  Male|  Divnomorskoye|Budget/Accounting...|61489.23|61489.23| 61489.23|\n",
            "|  Male|      Mytishchi|            VP Sales|63863.09|63863.09| 63863.09|\n",
            "|Female|Kinsealy-Drinan|      Civil Engineer|30101.16|30101.16| 30101.16|\n",
            "|  Male|      Trélissac|Desktop Support T...|46116.36|46116.36| 46116.36|\n",
            "|  Male|         Heitan|VP Product Manage...| 73697.1| 73697.1|  73697.1|\n",
            "|  Male|       Arbeláez|Mechanical System...|68098.42|68098.42| 68098.42|\n",
            "|Female|       El Cardo|Nuclear Power Eng...|13604.63|13604.63| 13604.63|\n",
            "|Female|    Wangqingtuo|Systems Administr...| 73423.7| 73423.7|  73423.7|\n",
            "|  Male|      Sułkowice|Compensation Analyst|33432.99|33432.99| 33432.99|\n",
            "|  Male|    Springfield|Assistant Media P...|50838.53|50838.53| 50838.53|\n",
            "|  Male|         Chrást|  Analyst Programmer|40163.03|40163.03| 40163.03|\n",
            "|  Male|         Xijiao|              Editor|32492.73|32492.73| 32492.73|\n",
            "|Female|      Mieścisko|Research Assistan...|51862.48|51862.48| 51862.48|\n",
            "|  Male| Foros do Trapo|     Design Engineer|42135.67|42135.67| 42135.67|\n",
            "|Female|    Jabungsisir|Senior Financial ...|91925.08|91925.08| 91925.08|\n",
            "|  Male|          Pedra| Staff Accountant IV|73921.33|73921.33| 73921.33|\n",
            "|  Male|          Xin’e|     Web Developer I|62755.85|62755.85| 62755.85|\n",
            "|  Male|         Xijiao|         Developer I|13708.03|13708.03| 13708.03|\n",
            "+------+---------------+--------------------+--------+--------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for training by converting categorical variables to numeric using StringIndexer\n",
        "gender_indexer = StringIndexer(inputCol=\"gender\", outputCol=\"genderIndex\")\n",
        "job_title_indexer = StringIndexer(inputCol=\"JobTitle\", outputCol=\"JobTitleIndex\")\n",
        "city_indexer = StringIndexer(inputCol=\"City\", outputCol=\"CityIndex\")\n",
        "\n",
        "df = gender_indexer.fit(df).transform(df)\n",
        "df = job_title_indexer.fit(df).transform(df)\n",
        "df = city_indexer.fit(df).transform(df)\n"
      ],
      "metadata": {
        "id": "HAAEfLdSvKqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression "
      ],
      "metadata": {
        "id": "xaC8vhV73ht8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for training by combining the features into a single vector\n",
        "assembler = VectorAssembler(inputCols=[\"genderIndex\", \"CityIndex\", \"JobTitleIndex\", \"Latitude\",\"Longitude\"],\n",
        "                            outputCol=\"features\")\n",
        "data = assembler.transform(df).select(\"features\", \"Salary\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "\n",
        "# Train a linear regression model on the training data\n",
        "lr = LinearRegression(labelCol=\"Salary\", featuresCol=\"features\")\n",
        "model = lr.fit(trainingData)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Evaluate the performance of the model using RMSE\n",
        "evaluator = RegressionEvaluator(labelCol=\"Salary\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "# Print the RMSE of the model\n",
        "print(\"Root Mean Squared Error (RMSE) = %g\" % rmse)\n",
        "\n",
        "# Show the coefficients and intercept of the linear regression model\n",
        "print(\"Coefficients: %s\" % str(model.coefficients))\n",
        "print(\"Intercept: %s\" % str(model.intercept))"
      ],
      "metadata": {
        "id": "QHl8_MsZmvPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a25a3ca-6c9a-4cf8-9c43-b712b122af32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) = 0.000149844\n",
            "Coefficients: [0.0002671763409683114,-2.7001771699159474e-07,-1.8263218471722112e-07,0.5000000000978084,0.5000000000978084]\n",
            "Intercept: -2.847271534037752e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifiction"
      ],
      "metadata": {
        "id": "c7rLPaE1FIMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Prepare the data for training by combining the features into a single vector\n",
        "assembler = VectorAssembler(inputCols=[\"genderIndex\", \"CityIndex\", \"JobTitleIndex\", \"Latitude\",\"Longitude\"],\n",
        "                            outputCol=\"features\")\n",
        "data = assembler.transform(df).select(\"features\", \"genderIndex\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Train a decision tree model on the training data\n",
        "lr = LogisticRegression(labelCol=\"genderIndex\", featuresCol=\"features\")\n",
        "model = lr.fit(trainingData)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Evaluate the performance of the model using AUC-ROC\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"genderIndex\")\n",
        "auc_roc = evaluator.evaluate(predictions)\n",
        "\n",
        "# Print the AUC-ROC of the model\n",
        "print(\"Area Under ROC = %g\" % auc_roc)\n",
        "\n",
        "# Show the coefficients and intercept of the logistic regression model\n",
        "print(\"Coefficients: %s\" % str(model.coefficients))\n",
        "print(\"Intercept: %s\" % str(model.intercept))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl-oqNu4Dtgb",
        "outputId": "b935ac27-bd5f-4d5a-8c2b-94ddbe555018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area Under ROC = 1\n",
            "Coefficients: [37.99244980169675,5.293395765998999e-07,0.00010444676682240483,-6.6830712682331e-08,-6.683071268078985e-08]\n",
            "Intercept: -19.01148095500658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree"
      ],
      "metadata": {
        "id": "PCjVnTPp3j4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://mldataset0123.s3.amazonaws.com/iris.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPjh_ZwYAWeV",
        "outputId": "c4f3e297-54ca-4dd9-b585-eb1b654c9679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-20 03:23:36--  https://mldataset0123.s3.amazonaws.com/iris.csv\n",
            "Resolving mldataset0123.s3.amazonaws.com (mldataset0123.s3.amazonaws.com)... 52.216.236.235, 3.5.10.23, 52.217.67.84, ...\n",
            "Connecting to mldataset0123.s3.amazonaws.com (mldataset0123.s3.amazonaws.com)|52.216.236.235|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4615 (4.5K) [text/csv]\n",
            "Saving to: ‘iris.csv’\n",
            "\n",
            "\riris.csv              0%[                    ]       0  --.-KB/s               \riris.csv            100%[===================>]   4.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-20 03:23:36 (258 MB/s) - ‘iris.csv’ saved [4615/4615]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset from a CSV file\n",
        "iris = spark.read.csv(\"iris.csv\", header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "species_indexer = StringIndexer(inputCol=\"species\", outputCol=\"speciesIndex\")\n",
        "\n",
        "iris = species_indexer.fit(iris).transform(iris)"
      ],
      "metadata": {
        "id": "BpGsPrlPDN7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.groupBy('speciesIndex').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyd4ov8FDPEV",
        "outputId": "82dc95af-9fe4-416e-fd77-6153532fe2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "|speciesIndex|count|\n",
            "+------------+-----+\n",
            "|         0.0|   50|\n",
            "|         1.0|   50|\n",
            "|         2.0|   50|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Prepare the data for training by combining the features into a single vector\n",
        "assembler = VectorAssembler(inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
        "                            outputCol=\"features\")\n",
        "data = assembler.transform(iris).select(\"features\", \"speciesIndex\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Train a decision tree model on the training data\n",
        "dt = DecisionTreeClassifier(labelCol=\"speciesIndex\", featuresCol=\"features\")\n",
        "model = dt.fit(trainingData)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Evaluate the accuracy of the model using the F1 score\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"speciesIndex\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print(\"Accuracy = %g\" % accuracy)\n",
        "\n",
        "# Show the decision tree rules\n",
        "print(\"Learned classification tree model:\")\n",
        "print(model.toDebugString)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuNdFFQZ3lEk",
        "outputId": "54b97194-02a6-4990-a754-2fd895d56cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.908435\n",
            "Learned classification tree model:\n",
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_c988c4e1b25b, depth=4, numNodes=13, numClasses=3, numFeatures=4\n",
            "  If (feature 2 <= 2.35)\n",
            "   Predict: 0.0\n",
            "  Else (feature 2 > 2.35)\n",
            "   If (feature 2 <= 4.95)\n",
            "    If (feature 3 <= 1.65)\n",
            "     Predict: 1.0\n",
            "    Else (feature 3 > 1.65)\n",
            "     If (feature 1 <= 2.8499999999999996)\n",
            "      Predict: 2.0\n",
            "     Else (feature 1 > 2.8499999999999996)\n",
            "      Predict: 1.0\n",
            "   Else (feature 2 > 4.95)\n",
            "    If (feature 3 <= 1.65)\n",
            "     If (feature 3 <= 1.55)\n",
            "      Predict: 2.0\n",
            "     Else (feature 3 > 1.55)\n",
            "      Predict: 1.0\n",
            "    Else (feature 3 > 1.65)\n",
            "     Predict: 2.0\n",
            "\n"
          ]
        }
      ]
    }
  ]
}